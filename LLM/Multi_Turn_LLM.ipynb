{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad92e16-4b6a-47bd-9a75-94881632e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client=OpenAI(api_key='sk-xda15eTImv62SYVb1eXw_2lOEvH7oRfCUFadCTgoEjT3BlbkFJHHPrtTsKyGtST8dcRBU3BZBSvcrW06fHTy9UP2wbMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86db904e-448d-4e72-a1a3-f969f3672d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-8EUv4G7jsPHtfdDr3N7Mzh', bytes=162475, created_at=1737215808, filename='updated_training_file.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "training_file=client.files.create(file=open('Data_LLM/updated_training_file.jsonl','rb'),\n",
    "                    purpose='fine-tune')\n",
    "print(training_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "471a9fe1-6fce-45cd-9e7b-56eda21d26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-m1XHiowosbmwRfxE96e8cQDi', created_at=1730839891, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-AVOdG0yGREZO41elnVjY6u7y', result_files=[], seed=1116585610, status='validating_files', trained_tokens=None, training_file='file-1GlMjMOy8euSwAsG9YFaqetC', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "response=client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model='gpt-4o-mini-2024-07-18')\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4ea26e-a69a-4012-bf35-36a4d281dab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-m1XHiowosbmwRfxE96e8cQDi', created_at=1730839891, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AQLEqzTY', finished_at=1730841530, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-AVOdG0yGREZO41elnVjY6u7y', result_files=['file-7y3JtKUuaqQN3VK3PjsRdkzi'], seed=1116585610, status='succeeded', trained_tokens=98664, training_file='file-1GlMjMOy8euSwAsG9YFaqetC', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None, method=None)\n"
     ]
    }
   ],
   "source": [
    "ft_model=client.fine_tuning.jobs.retrieve(\"ftjob-m1XHiowosbmwRfxE96e8cQDi\")#(response.id)\n",
    "print(ft_model)\n",
    "\n",
    "#fined_tune_model_id: ftjob-m1XHiowosbmwRfxE96e8cQDi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03374b20-1819-4368-af28-50fd396ed5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "messages=[]\n",
    "def generate_new_TSMP(role,prompt_content):\n",
    "    # Call the completion API with the given prompt\n",
    "    global messages\n",
    "    propmt={\"role\":role, \"content\": prompt_content}\n",
    "    messages.append(propmt)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=ft_model.fine_tuned_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    result = completion.choices[0].message.content\n",
    "    if '\\EOC' in result:\n",
    "        messages=[]\n",
    "        result=result[:-4]\n",
    "    else:\n",
    "        messages.append({\"role\":'assistant', \"content\": result})\n",
    "    \n",
    "    # Print the response from the assistant\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95e1a43-1d33-494c-b5e7-fe37bb9127de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Please suggest a TSMP\n",
      "Assistant:  I can generate a TSMP. Would you prefer it based on groups or properties?\n",
      "User:  Let's focus on property-based TSMP\n",
      "Assistant:  Okay, I can work with two properties: Tg and Er. What values should I target?\n",
      "User:  I need a TSMP which glass transition temperature=150C and stress recovery value=100Mpa\n",
      "Assistant:  Got it. Creating a TSMP with Tg=150C and Er=100MPa...\n"
     ]
    }
   ],
   "source": [
    "prompt_content_0 = \"Please suggest a TSMP\"\n",
    "replies_0=generate_new_TSMP('user',prompt_content_0)\n",
    "print(\"User: \", prompt_content_0)\n",
    "print(\"Assistant: \", replies_0)\n",
    "prompt_content_1=\"Let's focus on property-based TSMP\"\n",
    "replies_1=generate_new_TSMP('user',prompt_content_1)\n",
    "print(\"User: \", prompt_content_1)\n",
    "print(\"Assistant: \", replies_1)\n",
    "prompt_content_2=\"I need a TSMP which glass transition temperature=150C and stress recovery value=100Mpa\"\n",
    "replies_2=generate_new_TSMP('user',prompt_content_2)\n",
    "print(\"User: \", prompt_content_2)\n",
    "print(\"Assistant: \", replies_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38484d52-0800-4a17-9916-6f03af0c6b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  I need a thermoset shape memory polymer\n",
      "Assistant:  I can create a TSMP for you. Would you prefer it based on groups or properties?\n",
      "User:  I want a group-based TSMP\n",
      "Assistant:  Could you specify the group for the TSMP? Options include Vinyl (C=C), imine (C=N), and epoxy (C1OC1). Please remember that my training data has limitations.\n",
      "User:  please give a TSMP which has epoxy group\n",
      "Assistant:  Generating a TSMP with Epoxy group as requested.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt_content_3 = \"I need a thermoset shape memory polymer\"\n",
    "replies_3=generate_new_TSMP('user',prompt_content_3)\n",
    "print(\"User: \", prompt_content_3)\n",
    "print(\"Assistant: \", replies_3)\n",
    "prompt_content_4=\"I want a group-based TSMP\"\n",
    "replies_4=generate_new_TSMP('user',prompt_content_4)\n",
    "print(\"User: \", prompt_content_4)\n",
    "print(\"Assistant: \", replies_4)\n",
    "prompt_content_5=\"please give a TSMP which has epoxy group\"\n",
    "replies_5=generate_new_TSMP('user',prompt_content_5)\n",
    "print(\"User: \", prompt_content_5)\n",
    "print(\"Assistant: \", replies_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "243f0805-7fc3-413c-a011-d699d3b25f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Please suggest a TSMP\n",
      "Assistant:  I can create a TSMP for you. Would you prefer it based on groups or properties?\n",
      "User:  Let's focus on property-based TSMP\n",
      "Assistant:  The TSMP can focus on two properties: Tg and Er. What values do you need?\n",
      "User:  I need a TSMP which Tg=300 and Er=800\n",
      "Assistant:  Got it. Creating a TSMP with Tg=300 and Er=800...\n"
     ]
    }
   ],
   "source": [
    "prompt_content_0 = \"Please suggest a TSMP\"\n",
    "replies_0=generate_new_TSMP('user',prompt_content_0)\n",
    "print(\"User: \", prompt_content_0)\n",
    "print(\"Assistant: \", replies_0)\n",
    "prompt_content_1=\"Let's focus on property-based TSMP\"\n",
    "replies_1=generate_new_TSMP('user',prompt_content_1)\n",
    "print(\"User: \", prompt_content_1)\n",
    "print(\"Assistant: \", replies_1)\n",
    "prompt_content_2=\"I need a TSMP which Tg=300 and Er=800\"\n",
    "replies_2=generate_new_TSMP('user',prompt_content_2)\n",
    "print(\"User: \", prompt_content_2)\n",
    "print(\"Assistant: \", replies_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "244419c2-812a-4717-b296-c01c10728a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  I need a thermoset shape memory polymer\n",
      "Assistant:  Alright, you need a TSMP. Would you prefer it group-based or property-based?\n",
      "User:  Let's focus on group-based TSMP\n",
      "Assistant:  Which group would you like in the TSMP? For example: Vinyl (C=C), imine (C=N), epoxy (C1OC1). Note, not all groups are available in my training data.\n",
      "User:  please give a TSMP which has Epoxy group\n",
      "Assistant:  Generating a TSMP with Epoxy group as requested.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt_content_3 = \"I need a thermoset shape memory polymer\"\n",
    "replies_3=generate_new_TSMP('user',prompt_content_3)\n",
    "print(\"User: \", prompt_content_3)\n",
    "print(\"Assistant: \", replies_3)\n",
    "prompt_content_4=\"Let's focus on group-based TSMP\"\n",
    "replies_4=generate_new_TSMP('user',prompt_content_4)\n",
    "print(\"User: \", prompt_content_4)\n",
    "print(\"Assistant: \", replies_4)\n",
    "prompt_content_5=\"please give a TSMP which has Epoxy group\"\n",
    "replies_5=generate_new_TSMP('user',prompt_content_5)\n",
    "print(\"User: \", prompt_content_5)\n",
    "print(\"Assistant: \", replies_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1e624e92-d33b-492d-ae5c-06fa47ac2c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Can you give a TSMP which has imiine group\n",
      "Assistant:  Understood! Designing a TSMP with an Imine group as requested.\n"
     ]
    }
   ],
   "source": [
    "prompt_content_s=\"Can you give a TSMP which has imiine group\"\n",
    "replies_s=generate_new_TSMP('user',prompt_content_s)\n",
    "print(\"User: \", prompt_content_s)\n",
    "print(\"Assistant: \", replies_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6035eb12-4f8c-4194-8766-19f1085d74ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Please design a TSMP which has glass transition temperature of 150C and stress recovery value of 500mpa\n",
      "Assistant:  You need a TSMP with Tg=150C and Er=500MPa. We are in the process of generating this polymer based on your requirements...\n"
     ]
    }
   ],
   "source": [
    "prompt_content_t=\"Please design a TSMP which has glass transition temperature of 150C and stress recovery value of 500mpa\"\n",
    "replies_t=generate_new_TSMP('user',prompt_content)\n",
    "print(\"User: \", prompt_content_t)\n",
    "print(\"Assistant: \", replies_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4179b009-fe79-4342-9b08-d224a3a8fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='It looks like you might be interested in a property-based topic. Could you provide more specific details or tell me what you have in mind?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"Property based\"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "380c99c4-6fe2-49bd-bc48-67291d378eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Okay, you want a TSMP which has glass transition temperature=210 and stress recovery value=350. We are trying to generate a new TSMP based on your input...', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"I need a TSMP with glass transition temperature=210 and stress recovery value=350 \"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dd2c059-eabd-4ad4-9f9e-99296b259553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='I can create a TSMP for you. Would you prefer it based on groups or properties?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"I need a thermoset shape memory polymer\"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee4844f4-486d-4f00-bf71-825db4f8893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Got it! Do you want the group-based model to be predictive or generative?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"Let's focus on Group based\"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d1a0813-ec79-43f8-bfed-faf6bb91ce2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Okay, adding epoxy groups to the TSMP.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"I need a TSMP with epoxy groups\"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "006b2942-936c-4a41-b36c-1153752dac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Got it! Do you want the TSMP to be group-based or property-based?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='Got it! Should the group be based on characteristics or specific topics?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"I need a thermoset shape memory polymer\"\n",
    "generate_completion(prompt_content)\n",
    "prompt_content = \"Focus on groups\"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f57ee3f6-7b3f-4d71-95ad-be20502fcd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Creating a TSMP with vinyl groups as specified.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"I need a TSMP which has vinyl groups\"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e15c617b-0f93-4f49-996b-8609b985c4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Got it! Do you want the TSMP to be group-based or property-based?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='Got it! Do you want the group to be based on specific attributes or properties?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "prompt_content = \"I need a TSMP\"\n",
    "generate_completion(prompt_content)\n",
    "prompt_content = \"Group-based.\"\n",
    "generate_completion(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a77005a7-0cd2-4c4d-9ab4-d4e004374e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_entities(file_path):\n",
    "    entities = []\n",
    "    \n",
    "    # Open and read each line (JSON entity) from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            entity = json.loads(line.strip())  # Parse JSON and strip any extra whitespace\n",
    "            entities.append(entity)\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def update_and_save_entities_as_individual_lines(input_file_path, output_file_path):\n",
    "    # Read entities from the input file\n",
    "    entities = read_json_entities(input_file_path)\n",
    "    \n",
    "    # Open the output file in write mode\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        # Update each entity and write it as a single line in JSONL format\n",
    "        for entity in entities:\n",
    "            if 'messages' in entity and len(entity['messages']) > 5:\n",
    "                entity['messages'][5]['content'] += '\\EOC'\n",
    "            if 'messages' in entity and len(entity['messages']) ==2:\n",
    "                entity['messages'][1]['content'] += '\\EOC'\n",
    "            json.dump(entity, output_file)\n",
    "            output_file.write('\\n')  # Newline to separate each JSON entity\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'Data_LLM/merged_output.json'  # Replace with your actual file path\n",
    "output_file_path = 'Data_LLM/updated_output.jsonl'\n",
    "update_and_save_entities_as_individual_lines(input_file_path, output_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893ac22-2c19-4fbb-b846-9d9fc3936e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
